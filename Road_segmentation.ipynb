{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPrS6hyK2ENVhPxahY0sQrq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hoanganhphan0409/Road_segmentation/blob/main/Road_segmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dowload dataset"
      ],
      "metadata": {
        "id": "4aUx6xx856db"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "--FIwGg34u_1",
        "outputId": "7530fa42-adc2-4129-d05e-852a433e9515"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/Lane segmentation dataset/cityscapes_data\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KD5i3Gckinlj",
        "outputId": "e103a020-8ff0-4d78-9280-0fbdae5b1e37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Lane segmentation dataset/cityscapes_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import tensorflow as tf\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "xN6Mgy0omRH9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "id_map = {\n",
        "    0: (0, 0, 0), # unlabelled\n",
        "    1: (111, 74,  0), #static\n",
        "    2: ( 81,  0, 81), #ground\n",
        "    3: (128, 64,127), #road\n",
        "    4: (244, 35,232), #sidewalk\n",
        "    5: (250,170,160), #parking\n",
        "    6: (230,150,140), #rail track\n",
        "    7: (70, 70, 70), #building\n",
        "    8: (102,102,156), #wall\n",
        "    9: (190,153,153), #fence\n",
        "    10: (180,165,180), #guard rail\n",
        "    11: (150,100,100), #bridge\n",
        "    12: (150,120, 90), #tunnel\n",
        "    13: (153,153,153), #pole\n",
        "    14: (153,153,153), #polegroup\n",
        "    15: (250,170, 30), #traffic light\n",
        "    16: (220,220,  0), #traffic sign\n",
        "    17: (107,142, 35), #vegetation\n",
        "    18: (152,251,152), #terrain\n",
        "    19: ( 70,130,180), #sky\n",
        "    20: (220, 20, 60), #person\n",
        "    21: (255,  0,  0), #rider\n",
        "    22: (  0,  0,142), #car\n",
        "    23: (  0,  0, 70), #truck\n",
        "    24: (  0, 60,100), #bus\n",
        "    25: (  0,  0, 90), #caravan\n",
        "    26: (  0,  0,110), #trailer\n",
        "    27: (  0, 80,100), #train\n",
        "    28: (  0,  0,230), #motorcycle\n",
        "    29: (119, 11, 32), #bicycle\n",
        "    30: (  0,  0,142) #license plate \n",
        "}"
      ],
      "metadata": {
        "id": "goJUb-RQO5v2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(path):\n",
        "    img = Image.open(path)\n",
        "    img1 = img.crop((0, 0, 256, 256)).resize((128, 128))\n",
        "    img2 = img.crop((256, 0, 512, 256)).resize((128, 128))\n",
        "    img1 = np.array(img1) / 255.\n",
        "    img2 = np.array(img2)\n",
        "    mask = np.zeros(shape=(img2.shape[0], img2.shape[1]), dtype = np.uint32)\n",
        "    for row in range(img2.shape[0]):\n",
        "        for col in range(img2.shape[1]):\n",
        "            a = img2[row, col, :]\n",
        "            final_key = None\n",
        "            final_d = None\n",
        "            for key, value in id_map.items():\n",
        "                d = np.sum(np.sqrt(pow(a - value, 2)))\n",
        "                if final_key == None:\n",
        "                    final_d = d\n",
        "                    final_key = key\n",
        "                elif d < final_d:\n",
        "                    final_d = d\n",
        "                    final_key = key\n",
        "            mask[row, col] = final_key\n",
        "            if final_key != 3:\n",
        "                mask[row, col] = 0\n",
        "                       \n",
        "    mask = np.reshape(mask, (mask.shape[0], mask.shape[1], 1))\n",
        "    del img2\n",
        "    return img1, mask\n",
        "\n",
        "def prepare_tensor_dataset(train_path, val_path):\n",
        "    X_train = []\n",
        "    Y_train = []\n",
        "    X_val = []\n",
        "    Y_val = []\n",
        "    for file in tqdm(os.listdir(train_path)):\n",
        "        img, mask = preprocess(f\"{train_path}/{file}\")\n",
        "        X_train.append(img)\n",
        "        Y_train.append(mask)\n",
        "    \n",
        "    for file in tqdm(os.listdir(val_path)):\n",
        "        img, mask = preprocess(f\"{val_path}/{file}\")\n",
        "        X_val.append(img)\n",
        "        Y_val.append(mask)\n",
        "\n",
        "    return X_train, Y_train, X_val, Y_val"
      ],
      "metadata": {
        "id": "a6SOx8bBPCKA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, Y_train, X_valid, Y_valid = prepare_tensor_dataset(\"/content/drive/MyDrive/Lane segmentation dataset/cityscapes_data/train\",\"/content/drive/MyDrive/Lane segmentation dataset/cityscapes_data/val\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3FU_gsU0PeTf",
        "outputId": "1edc4105-31c7-48f3-b27e-8fcc5b7e33ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2975/2975 [4:28:59<00:00,  5.42s/it]\n",
            "100%|██████████| 500/500 [42:42<00:00,  5.12s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = np.array(X_train)\n",
        "Y_train = np.array(Y_train)\n",
        "X_valid = np.array(X_valid)\n",
        "Y_valid = np.array(Y_valid)"
      ],
      "metadata": {
        "id": "vAQiqLkkQFb3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_unet_model():\n",
        "    \n",
        "    inputs = tf.keras.layers.Input(shape = [128, 128, 3])\n",
        "    \n",
        "    #First Downsample\n",
        "    f1 = tf.keras.layers.Conv2D(64, kernel_size = (3, 3), padding = \"same\", strides = 1, activation = \"relu\")(inputs)\n",
        "    b1 = tf.keras.layers.BatchNormalization()(f1)\n",
        "    f2 = tf.keras.layers.Conv2D(64, kernel_size = (3, 3), padding = \"same\", strides = 1, activation = \"relu\")(b1)    # Used later for residual connection\n",
        "    \n",
        "    m3 = tf.keras.layers.MaxPooling2D(pool_size = (2, 2), strides = 2)(f2)\n",
        "    d4 = tf.keras.layers.Dropout(0.2)(m3)\n",
        "    \n",
        "    # Second Downsample\n",
        "    f5 = tf.keras.layers.Conv2D(128, kernel_size = (3, 3), padding = \"same\", strides = 1, activation = \"relu\")(d4)\n",
        "    b5 = tf.keras.layers.BatchNormalization()(f5)\n",
        "    f6 = tf.keras.layers.Conv2D(128, kernel_size = (3, 3), padding = \"same\", strides = 1, activation = \"relu\")(b5)    # Used later for residual connection\n",
        "    \n",
        "    m7 = tf.keras.layers.MaxPooling2D(pool_size = (2, 2), strides = 2)(f6)\n",
        "    d8 = tf.keras.layers.Dropout(0.2)(m7)\n",
        "    \n",
        "    # Third Downsample\n",
        "    f9 = tf.keras.layers.Conv2D(256, kernel_size = (3, 3), padding = \"same\", strides = 1, activation = \"relu\")(d8)\n",
        "    b9 = tf.keras.layers.BatchNormalization()(f9)\n",
        "    f10 = tf.keras.layers.Conv2D(256, kernel_size = (3, 3), padding = \"same\", strides = 1, activation = \"relu\")(b9)    # Used later for residual connection\n",
        "    \n",
        "    m11 = tf.keras.layers.MaxPooling2D(pool_size = (2, 2), strides = 2)(f10)\n",
        "    d12 = tf.keras.layers.Dropout(0.2)(m11)\n",
        "    \n",
        "    #Forth Downsample\n",
        "    f13 = tf.keras.layers.Conv2D(512, kernel_size = (3, 3), padding = \"same\", strides = 1, activation = \"relu\")(d12)\n",
        "    b13 = tf.keras.layers.BatchNormalization()(f13)\n",
        "    f14 = tf.keras.layers.Conv2D(512, kernel_size = (3, 3), padding = \"same\", strides = 1, activation = \"relu\")(b13)    # Used later for residual connection\n",
        "    \n",
        "    m15 = tf.keras.layers.MaxPooling2D(pool_size = (2, 2), strides = 2)(f14)\n",
        "    d16 = tf.keras.layers.Dropout(0.2)(m15)\n",
        "    \n",
        "    #Fifth Downsample\n",
        "    f17 = tf.keras.layers.Conv2D(1024, kernel_size = (3, 3), padding = \"same\", strides = 1, activation = \"relu\")(d16)\n",
        "    b17 = tf.keras.layers.BatchNormalization()(f17)\n",
        "    f18 = tf.keras.layers.Conv2D(1024, kernel_size = (3, 3), padding = \"same\", strides = 1, activation = \"relu\")(b17)\n",
        "\n",
        "    \n",
        "    # First Upsample\n",
        "    m19 = tf.keras.layers.UpSampling2D(size = (2, 2))(f18)\n",
        "    d19 = tf.keras.layers.Dropout(0.2)(m19)\n",
        "    c20 = tf.keras.layers.Concatenate()([d19, f14])\n",
        "    f21 = tf.keras.layers.Conv2D(512, kernel_size = (3, 3), padding = \"same\", strides = 1 ,activation = \"relu\")(c20)\n",
        "    b21 = tf.keras.layers.BatchNormalization()(f21)\n",
        "    f22 = tf.keras.layers.Conv2D(512, kernel_size = (3, 3), padding = \"same\", strides = 1, activation = \"relu\")(b21)\n",
        "    \n",
        "    # Second Upsample\n",
        "    m23 = tf.keras.layers.UpSampling2D(size = (2, 2))(f22)\n",
        "    d23 = tf.keras.layers.Dropout(0.2)(m23)\n",
        "    c24 = tf.keras.layers.Concatenate()([d23, f10])\n",
        "    f25 = tf.keras.layers.Conv2D(256, kernel_size = (3, 3), padding = \"same\", strides = 1, activation = \"relu\")(c24)\n",
        "    b25 = tf.keras.layers.BatchNormalization()(f25)\n",
        "    f26 = tf.keras.layers.Conv2D(256, kernel_size = (3, 3), padding = \"same\", strides = 1, activation = \"relu\")(b25)\n",
        "    \n",
        "    # Third Upsample\n",
        "    m27 = tf.keras.layers.UpSampling2D(size = (2, 2))(f26)\n",
        "    d27 = tf.keras.layers.Dropout(0.2)(m27)\n",
        "    c28 = tf.keras.layers.Concatenate()([d27, f6])\n",
        "    f29 = tf.keras.layers.Conv2D(128, kernel_size = (3, 3), padding = \"same\", strides = 1, activation = \"relu\")(c28)\n",
        "    b29 = tf.keras.layers.BatchNormalization()(f29)\n",
        "    f30 = tf.keras.layers.Conv2D(128, kernel_size = (3, 3), padding = \"same\", strides = 1, activation = \"relu\")(b29)\n",
        "    \n",
        "    #Forth Upsample\n",
        "    m31 = tf.keras.layers.UpSampling2D(size = (2, 2))(f30)\n",
        "    d31 = tf.keras.layers.Dropout(0.2)(m31)\n",
        "    c32 = tf.keras.layers.Concatenate()([d31, f2])\n",
        "    f33 = tf.keras.layers.Conv2D(64, kernel_size = (3, 3), padding = \"same\", strides = 1, activation = \"relu\")(c32)\n",
        "    b33 = tf.keras.layers.BatchNormalization()(f33)\n",
        "    f34 = tf.keras.layers.Conv2D(64, kernel_size = (3, 3), padding = \"same\", strides = 1, activation = \"relu\")(b33)\n",
        "    \n",
        "    # Output Layer\n",
        "    outputs = tf.keras.layers.Conv2D(1,kernel_size = (3, 3), padding = \"same\", strides = 1, activation = \"softmax\")(f34)\n",
        "    \n",
        "    model = tf.keras.Model(inputs = [inputs], outputs = [outputs])\n",
        "    return model"
      ],
      "metadata": {
        "id": "dnYQEc4ZbpRU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = get_unet_model()"
      ],
      "metadata": {
        "id": "KzpzaQRkb33f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class VizCallback(tf.keras.callbacks.Callback):\n",
        "    \n",
        "    def __init__(self, file_path, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.file_path = file_path\n",
        "    \n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        img, mask = preprocess(self.file_path)\n",
        "        img = np.array(img)\n",
        "        img = np.reshape(img, (1, 128, 128, 3))\n",
        "        pred = model.predict(img)\n",
        "        y_pred = tf.math.argmax(pred, axis=-1)\n",
        "        y_pred = np.array(y_pred)\n",
        "        y_pred = np.reshape(y_pred, (128, 128))\n",
        "        fig, axes = plt.subplots(nrows = 1, ncols = 2)\n",
        "        axes[0].imshow(mask)\n",
        "        axes[0].set_title(\"Original Mask\")\n",
        "        axes[1].imshow(y_pred)\n",
        "        axes[1].set_title(\"Predicted Mask\")\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "def plot_history(history):\n",
        "  fig, axes = plt.subplots(nrows = 1, ncols = 3, figsize=(20, 7))\n",
        "  # Training\n",
        "  sns.lineplot(range(1, len(history.history[\"loss\"]) + 1), history.history[\"loss\"], ax = axes[0], label=\"Training Loss\")\n",
        "  sns.lineplot(range(1, len(history.history[\"loss\"]) + 1), history.history[\"accuracy\"], ax = axes[1], label=\"Training Accuracy\")\n",
        "\n",
        "  # Validation\n",
        "  sns.lineplot(range(1, len(history.history[\"loss\"]) + 1), history.history[\"val_loss\"], ax = axes[0], label=\"Validation Loss\")\n",
        "  sns.lineplot(range(1, len(history.history[\"loss\"]) + 1), history.history[\"val_accuracy\"], ax = axes[1], label=\"Validation Accuracy\")\n",
        "  axes[0].set_title(\"Loss Comparison\", fontdict = {'fontsize': 15})\n",
        "  axes[0].set_xlabel(\"Epoch\")\n",
        "  axes[0].set_ylabel(\"Loss\")\n",
        "\n",
        "  axes[1].set_title(\"Accuracy Comparison\", fontdict = {'fontsize': 15})\n",
        "  axes[1].set_xlabel(\"Epoch\")\n",
        "  axes[1].set_ylabel(\"Accuracy\")\n",
        "  plt.tight_layout()\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "ahrAGH_SFSNV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss = \"sparse_categorical_crossentropy\", optimizer = \"adam\", metrics = [\"accuracy\"])"
      ],
      "metadata": {
        "id": "5wGHZKH0baId"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(x=X_train, y=Y_train, epochs = 100, batch_size = 32, validation_data = (X_valid, Y_valid))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0MI8BBCecZcy",
        "outputId": "71d7e596-af62-4b7e-990b-a402d2e049cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "93/93 [==============================] - 44s 453ms/step - loss: nan - accuracy: 0.6689 - val_loss: nan - val_accuracy: 0.6735\n",
            "Epoch 2/100\n",
            "93/93 [==============================] - 42s 447ms/step - loss: nan - accuracy: 0.6763 - val_loss: nan - val_accuracy: 0.6735\n",
            "Epoch 3/100\n",
            "93/93 [==============================] - 42s 449ms/step - loss: nan - accuracy: 0.6763 - val_loss: nan - val_accuracy: 0.6735\n",
            "Epoch 4/100\n",
            "93/93 [==============================] - 42s 448ms/step - loss: nan - accuracy: 0.6763 - val_loss: nan - val_accuracy: 0.6735\n",
            "Epoch 5/100\n",
            "93/93 [==============================] - 42s 447ms/step - loss: nan - accuracy: 0.6763 - val_loss: nan - val_accuracy: 0.6735\n",
            "Epoch 6/100\n",
            "93/93 [==============================] - 42s 448ms/step - loss: nan - accuracy: 0.6763 - val_loss: nan - val_accuracy: 0.6735\n",
            "Epoch 7/100\n",
            "93/93 [==============================] - 42s 448ms/step - loss: nan - accuracy: 0.6763 - val_loss: nan - val_accuracy: 0.6735\n",
            "Epoch 8/100\n",
            "93/93 [==============================] - 42s 447ms/step - loss: nan - accuracy: 0.6763 - val_loss: nan - val_accuracy: 0.6735\n",
            "Epoch 9/100\n",
            "93/93 [==============================] - 42s 448ms/step - loss: nan - accuracy: 0.6763 - val_loss: nan - val_accuracy: 0.6735\n",
            "Epoch 10/100\n",
            "93/93 [==============================] - 42s 448ms/step - loss: nan - accuracy: 0.6763 - val_loss: nan - val_accuracy: 0.6735\n",
            "Epoch 11/100\n",
            "93/93 [==============================] - 42s 447ms/step - loss: nan - accuracy: 0.6763 - val_loss: nan - val_accuracy: 0.6735\n",
            "Epoch 12/100\n",
            "93/93 [==============================] - 42s 448ms/step - loss: nan - accuracy: 0.6763 - val_loss: nan - val_accuracy: 0.6735\n",
            "Epoch 13/100\n",
            "93/93 [==============================] - 42s 450ms/step - loss: nan - accuracy: 0.6763 - val_loss: nan - val_accuracy: 0.6735\n",
            "Epoch 14/100\n",
            "93/93 [==============================] - 42s 447ms/step - loss: nan - accuracy: 0.6763 - val_loss: nan - val_accuracy: 0.6735\n",
            "Epoch 15/100\n",
            "93/93 [==============================] - 42s 447ms/step - loss: nan - accuracy: 0.6763 - val_loss: nan - val_accuracy: 0.6735\n",
            "Epoch 16/100\n",
            "93/93 [==============================] - 42s 448ms/step - loss: nan - accuracy: 0.6763 - val_loss: nan - val_accuracy: 0.6735\n",
            "Epoch 17/100\n",
            "93/93 [==============================] - 42s 448ms/step - loss: nan - accuracy: 0.6763 - val_loss: nan - val_accuracy: 0.6735\n",
            "Epoch 18/100\n",
            "93/93 [==============================] - 42s 447ms/step - loss: nan - accuracy: 0.6763 - val_loss: nan - val_accuracy: 0.6735\n",
            "Epoch 19/100\n",
            "93/93 [==============================] - 42s 448ms/step - loss: nan - accuracy: 0.6763 - val_loss: nan - val_accuracy: 0.6735\n",
            "Epoch 20/100\n",
            "93/93 [==============================] - 42s 448ms/step - loss: nan - accuracy: 0.6763 - val_loss: nan - val_accuracy: 0.6735\n",
            "Epoch 21/100\n",
            "93/93 [==============================] - 42s 447ms/step - loss: nan - accuracy: 0.6763 - val_loss: nan - val_accuracy: 0.6735\n",
            "Epoch 22/100\n",
            "93/93 [==============================] - 42s 447ms/step - loss: nan - accuracy: 0.6763 - val_loss: nan - val_accuracy: 0.6735\n",
            "Epoch 23/100\n",
            "83/93 [=========================>....] - ETA: 4s - loss: nan - accuracy: 0.6762"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ị"
      ],
      "metadata": {
        "id": "8i4Uk11DdN7k"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}